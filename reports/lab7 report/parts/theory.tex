\subsection{Метод максимального правдоподобия}
Одним из универсальных методов оценивания является метод максимального правдоподобия, предложенный Р.Фишером (1921).
Пусть $x_{1},...,x_{n}$ — случайная выборка из генеральной совокупности с плотностью вероятности $f(x,\theta$); $L(x_{1},... ,x_{n}, \theta)$ — функция правдоподобия (ФП), представляющая собой совместную плотность вероятности независимых с.в. $x_{1}, ... ,x_{n}$ и рассматриваемая как функция неизвестного параметра $\theta$:
\begin{equation}
L(x_{1},...,x_{n},\theta) = f(x_{1},\theta)f(x_{2},\theta)...f(x_{n}, \theta)
\label{L()}
\end{equation}
\textit{Определение}. Оценкой максимального правдоподобия (о.м.п) будем называть такое значение $\hat{\theta_{мп}}$ из множества допустимых значений параметра $\theta$, для которого ФП принимает наибольшее значение при заданных $x_{1},...,x_{n}$:
\begin{equation}
\hat{\theta_{мп}} = \arg \max_{\theta}L(x_{1},...,x_{n},\theta)
\label{theta_mp}
\end{equation}
Если ФП дважды дифференцируема, то её стационарные значения даются корнями уравнения
\begin{equation}
\frac{\partial L(x_{1},...,x_{n},\theta)}{\partial \theta} = 0
\label{eq_min}
\end{equation}
Достаточным условием того, чтобы некоторое стационарное значениe $\Tilde{\theta}$ было локальным максимумом, является неравенство
\begin{equation}
\frac{\partial^{2}L}{\partial \theta^{2}}(x_{1},...,x_{n},\Tilde{\theta}) < 0
\label{ineq_min}
\end{equation}
Определив точки локальных максимумов ФП (если их несколько), находят наибольший, который и даёт решение задачи (\ref{L()}).
Часто проще искать максимум логарифма ФП, так как он имеет максимум в одной точке с ФП:
\begin{equation}
\frac{\partial \ln L}{\partial \theta}=\frac{1}{L}\frac{\partial L}{\partial \theta}, если L > 0
\label{log_max}
\end{equation}
и соответственно решать уравнение
\begin{equation}
\frac{\partial \ln L}{\partial \theta}= 0
\label{log_m=0}
\end{equation}
которое называют \textit{уравнением правдоподобия}.
В задаче оценивания векторного параметра $\theta = (\theta_{1}, ... ,\theta_{m})$ аналогично (\ref{theta_mp}) находится максимум ФП нескольких аргументов: 
\begin{equation}
\hat{\theta_{мп}} = \arg \max_{\theta_{1}, \theta_{2}...\theta_{m}} L(x_{1}, x_{2},...x_{n}, \theta_{1}, \theta_{2},...\theta_{m})
\label{multi_theta}
\end{equation}
и в случае дифференцируемости ФП выписывается система уравнений правдоподобия
\begin{equation}
\frac{\partial L}{\partial \theta_{k}} = 0 \text{  или  } \frac{\partial \ln L}{\partial \theta_{k}} = 0, k = 1,..m
\end{equation}





\subsection{Проверка гипотезы о законе распределения генеральной совокупности. Метод хи-квадрат}
Исчерпывающей характеристикой изучаемой случайной величины является её закон распределения. Поэтому естественно стремление исследователей построить этот закон приближённо на основе статистических данных.
\newline
Сначала выдвигается гипотеза о виде закона распределения.
\newline
После того как выбран вид закона, возникает задача оценивания его параметров и проверки (тестирования) закона в целом.
\newline
Для проверки гипотезы о законе распределения применяются критерии согласия. Таких критериев существует много. Мы рассмотрим наиболее обоснованный и наиболее часто используемый в практике — критерий $\chi^{2}$ (хи-квадрат), введённый К.Пирсоном (1900 г.) для случая, когда параметры распределения известны. Этот критерий был существенно уточнён Р.Фишером (1924 г.), когда параметры распределения оцениваются по выборке, используемой для проверки.
\newline
Мы ограничимся рассмотрением случая одномерного распределения.
\newline
Итак, выдвинута гипотеза $H_{0}$ о генеральном законе распределения с функцией распределения F(x).
\newline
Рассматриваем случай, когда гипотетическая функция распределения F(x) не содержит неизвестных параметров.
\newline
Разобьём генеральную совокупность, т.е. множество значений изучаемой случайной величины X на k непересекающихся подмножеств $\Delta_{1},\Delta_{2}, ... ,\Delta_{k}$.
\newline
Пусть $p_{i} = P(X \in \Delta_{i}), i = 1, ... ,k$. 
\newline
Если генеральная совокупность $-$ вся вещественная ось, то подмножества $\Delta_i = (a_{i-1},a_{i}]$ $-$ полуоткрытые промежутки (i = 2, ... ,k$-$1). Крайние промежутки будут полубесконечными: $\Delta_{1} = (-\infty,a_{1}], \Delta_{k} = (a_{k-1},+\infty).$ В этом случае $p_{i} = F(a_{i})$$-$$F(a_{i-1}); a_{0} = -\infty, a_{k} = +\infty (i = 1, ... ,k).$
\newline
Отметим, что $\sum_{i=1}^{k}{p_{i}} = 1$.
Будем предполагать, что все $p_{i}$ > 0 (i = 1, ... ,k).
\newline
Пусть, далее, $n_{1},n_{2}, ... ,n_{k}$ — частоты попадания выборочных элементов в подмножества $\Delta_{1},\Delta_{2}, ... ,\Delta_{k}$ соответственно.
\newline
В случае справедливости гипотезы $H_{0}$ относительные частоты $n_{i}/n$ при большом n должны быть близки к вероятностям $p_{i}$ (i = 1, ... ,k), поэтому за меру отклонения выборочного распределения от гипотетического с функцией F(x) естественно выбрать величину
\begin{equation}
Z = \sum_{i = 1}^{k}{c_{i}(\frac{n_{i}}{n} - p_{i})^{2}}, 
\label{Z}
\end{equation}
где $c_{i}$ — какие-нибудь положительные числа (веса). К.Пирсоном в качестве весов выбраны числа $c_{i} = n/p_{i}$ (i = 1, ... ,k). Тогда получается статистика критерия хи-квадрат К.Пирсона
\begin{equation}
\chi^{2} = \sum_{i = 1}^{k}{\frac{n}{p_{i}}(\frac{n_{i}}{n} - p_{i})^{2}} = \sum_{i = 1}^{k}{\frac{(n_{i} - np_{i})^{2}}{np_{i}}}, 
\label{chi_2}
\end{equation}
которая обозначена тем же символом, что и закон распределения хи-квадрат.
\newline
К.Пирсоном доказана теорема об асимптотическом поведении статистики $\chi^{2}$, указывающая путь её применения.
\newline
\textit{Теорема К.Пирсона}. Статистика критерия $\chi^{2}$ асимптотически распределена по закону $\chi^{2}$ с $k-1$ степенями свободы.
\newline
Это означает, что независимо от вида проверяемого распределения, т.е. функции F(x), выборочная функция распределения статистики $\chi^{2}$ при $n \rightarrow \infty$  стремится к функции распределения случайной величины с плотностью вероятности 
\begin{equation}
f_{k - 1}(x) = 
\begin{cases}
& 0 \text{ , } x  \leq 0  \\ 
& \frac{1}{2^{\frac{k-1}{2}}\Gamma(\frac{k-1}{2})}x^{\frac{k-3}{2}}e^{-\frac{x}{2}}
\text{ , } x>0 
\end{cases}
\label{f_k-1}
\end{equation}
Для прояснения сущности метода $\chi^{2}$ сделаем ряд замечаний.
\newline
\textit{Замечание 1}. Выбор подмножеств $\Delta_{1},\Delta_{2}, ... ,\Delta_{k}$ и их числа k в принципе ничем не регламентируется, так как $n \rightarrow \infty$. Но так как число n хотя и очень большое, но конечное, то k должно быть с ним согласовано. Обычно его берут таким же, как и для построения гистограммы, т.е. можно руководствоваться формулой
\begin{equation}
k \approx 1.72\sqrt[3]{n}
\label{k_1}
\end{equation}
или формулой Старджесса
\begin{equation}
k \approx 1 + 3.3lgn
\end{equation}
При этом, если  $\Delta_{1},\Delta_{2}, ... ,\Delta_{k}$ — промежутки, то их длины удобно сделать равными, за исключением крайних — полубесконечных.
\newline
\textit{Замечание 2}. (о числе степеней свободы).
Числом степеней свободы функции (по старой терминологии) называется число её независимых аргументов. Аргументами статистики $\chi^{2}$ являются частоты $n_{1},n_{2}, ... ,n_{k}$. Эти частоты связаны одним равенством $n_{1} + n_{2} + ... + n_{k}  = n$, а в остальном независимы в силу независимости элементов выборки. Таким образом, функция $\chi^{2}$  имеет $k-1$ независимых аргументов: число частот минус одна связь. В силу теоремы Пирсона число степеней свободы статистики $\chi^{2}$  отражается на виде асимптотической плотности $f_{k - 1}(x)$.
\newline
На основе общей схемы проверки статистических гипотез сформулируем следующее правило.
\newline
\textit{Правило проверки гипотезы о законе распределения по методу $\chi^{2}$}.
\newline
1. Выбираем уровень значимости $\alpha$.
\newline
2. По таблице [3, с. 358] находим квантиль $\chi^{2}_{1-\alpha}(k - 1)$ распределения хи-квадрат с k$-$1 степенями свободы порядка $1-\alpha$. 
\newline
3. С помощью гипотетической функции распределения F(x) вычисляем вероятности $p_{i} = P (X \in \Delta_{i})$, i = 1, ... ,k.
\newline
4. Находим частоты $n_{i}$ попадания элементов выборки в подмножества $\Delta_{i}$, i = 1, ... ,k. 
\newline
5. Вычисляем выборочное значение статистики критерия $\chi^{2}$:
\begin{equation}
\chi^{2}_{B} =\sum_{i = 1}^{k}{\frac{(n_{i} - np_{i})^{2}}{np_{i}}}.
\label{chi_B}
\end{equation}
\newline
6. Сравниваем $\chi^{2}_{B}$ и квантиль $\chi^{2}_{1-\alpha}(k-1)$.
\newline
а) Если $\chi^{2}_{B}$ < $\chi^{2}_{1-\alpha}$(k $-$ 1), то гипотеза $H_{0}$ на данном этапе проверки принимается. 
\newline
б) Если $\chi^{2}_{B} >= \chi^{2}_{1-\alpha}(k -1)$, то гипотеза $H_{0}$ отвергается, выбирается одно из альтернативных распределений, и процедура проверки повторяется.
\newline
\textit{Замечание 3}. Из формулы (\ref{chi_2}) видим, что веса $c_i = n/p_{i}$ пропорциональны $n$, т.е. с ростом $n$ увеличиваются. Отсюда следует, что если выдвинутая гипотеза неверна, то относительные частоты $n_{i}/n$ не будут близки к вероятностям $p_{i}$, и с ростом n величина  $\chi^{2}_{B}$  будет увеличиваться. При фиксированном уровне значимости $\alpha$ будет фиксировано пороговое число - квантиль $\chi^{2}_{1-\alpha}(k-1)$, поэтому, увеличивая n, мы придём к неравенству $\chi^{2}_{B} > \chi^{2}_{1-\alpha}(k-1)$, т.е. с увеличением объёма выборки неверная гипотеза будет отвергнута.
\newline
Отсюда следует, что при сомнительной ситуации, когда $\chi^{2}_{B} \approx \chi^{2}_{1-\alpha}(k-1)$, можно попытаться увеличить объём выборки (например, в 2 раза), чтобы требуемое неравенство было более чётким.
\newline
\textit{Замечание 4}. Теория и практика применения критерия  $\chi^{2}$ указывают, что если для каких-либо подмножеств $\Delta_{i}$ (i = 1, ... ,k) условие $np_{i} \geq 5$ не выполняется, то следует объединить соседние подмножества (промежутки).
\newline
Это условие выдвигается требованием близости величин $\frac{(n_{i} -np_{i})}{\sqrt{np_{i}}}$, квадраты которых являются слагаемыми $\chi^{2}$  к нормальным N(0,1). Тогда случайная величина в формуле (\ref{chi_2}) будет распределена по закону, близкому к хи-квадрат. Такая близость обеспечивается достаточной численностью элементов в подмножествах $\Delta_{i}$ [1, с. 481-485].